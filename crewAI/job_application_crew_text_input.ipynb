{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Crew to Tailor Job Applications (Text Input Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "# configure the Phoenix tracer\n",
    "tracer_provider = register(\n",
    "  project_name=\"my-crewai-vertex-app\", # Default is 'default'\n",
    "  auto_instrument=True # Auto-instrument your app based on installed OI dependencies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gcloud auth application-default login before running this script\n",
    "# to set up the credentials for the Google Cloud SDK\n",
    "# and the Google Cloud client libraries.\n",
    "# SERPER API key is required for this example. \n",
    "# You can set it up in your environment variables or directly in the code.\n",
    "\n",
    "\n",
    "# ... other comments ...\n",
    "from crewai import LLM\n",
    "from google.auth import default\n",
    "\n",
    "credentials, _ = default()\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"vertex_ai/gemini-2.5-flash-preview-05-20\",\n",
    "    temperature=0.7,\n",
    "    credentials=credentials,\n",
    "    vertex_project=os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\"),\n",
    "    vertex_location=os.getenv(\"GOOGLE_CLOUD_PROJECT_REGION\"),\n",
    ")\n",
    "# Building a Job Application Assistant with CrewAI\n",
    "\n",
    "This notebook demonstrates how to build an automated job application assistant using CrewAI. The system takes a job description and personal information as input, then uses a team of specialized AI agents to:\n",
    "\n",
    "1. Research and analyze job requirements\n",
    "2. Profile the candidate's skills and experience\n",
    "3. Create a tailored resume that matches job requirements\n",
    "4. Prepare for interviews with custom materials\n",
    "\n",
    "Each agent has a specific role and expertise, working collaboratively to produce the best results.## Environment Setup\n",
    "\n",
    "This section configures the notebook environment, loads environment variables, and suppresses warnings to ensure a clean execution.# Suppress warnings and load environment variables from .env file\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Suppress warning messages\n",
    "load_dotenv(find_dotenv())  # Load environment variables from .env file## Telemetry Configuration\n",
    "\n",
    "Configure Phoenix tracer for monitoring and tracking the application's performance.## LLM Configuration\n",
    "\n",
    "Set up the Language Learning Model (LLM) that will power our agents. This notebook supports:\n",
    "- Google Vertex AI (Gemini model)\n",
    "- Groq API (configured to use Llama models)\n",
    "\n",
    "Before running this section, ensure you have:\n",
    "1. Set up Google Cloud credentials using `gcloud auth application-default login`\n",
    "2. Configured necessary API keys in your environment variables## CrewAI Setup\n",
    "\n",
    "Import the core components from CrewAI that we'll use to build our agent system:\n",
    "- `Agent`: Represents an AI agent with a specific role, goal, and capabilities\n",
    "- `Task`: Defines work to be done by an agent, including inputs and expected outputs\n",
    "- `Crew`: Coordinates multiple agents working together on related tasks## Tools Configuration\n",
    "\n",
    "Set up specialized tools that our agents will use to gather information and process data:\n",
    "- `FileReadTool`: Reads the contents of files (used to access the resume)\n",
    "- `MDXSearchTool`: Performs semantic search on markdown documents\n",
    "- `SerperDevTool`: Allows agents to search the web for relevant information## Agent Definitions\n",
    "\n",
    "Each agent in our crew has a specialized role in the job application process:\n",
    "\n",
    "1. **Researcher**: Analyzes job descriptions to extract key requirements and qualifications\n",
    "2. **Profiler**: Assesses the candidate's skills and experience against job requirements\n",
    "3. **Resume Strategist**: Creates a tailored resume that highlights relevant qualifications\n",
    "4. **Interview Preparer**: Develops materials to help prepare for interviews## Task Definitions\n",
    "\n",
    "Define the specific tasks that each agent will perform:\n",
    "\n",
    "1. **Research Task**: Extract and analyze job requirements\n",
    "2. **Profile Task**: Create a comprehensive candidate profile\n",
    "3. **Resume Strategy Task**: Develop a tailored resume\n",
    "4. **Interview Preparation Task**: Create interview preparation materials\n",
    "\n",
    "Tasks are connected through the `context` parameter, allowing the output of one task to feed into another.## Crew Configuration\n",
    "\n",
    "Create a crew that coordinates all agents and tasks. The crew manages:\n",
    "- The sequence of task execution\n",
    "- Information sharing between agents\n",
    "- Handling of inputs and outputs## Input Configuration and Execution\n",
    "\n",
    "Prepare the input data for our job application crew:\n",
    "1. **Job Description**: The full text of the target job posting\n",
    "2. **GitHub URL**: Link to the candidate's code portfolio\n",
    "3. **Personal Writeup**: A description of the candidate's background and qualifications\n",
    "\n",
    "Then execute the crew to generate tailored application materials.\n",
    "\n",
    "**Note**: Since LLMs can produce different outputs for the same input, your results may vary from run to run.## Results Visualization\n",
    "\n",
    "View the final outputs generated by our crew:\n",
    "1. **Tailored Resume**: A customized resume that emphasizes relevant skills and experience\n",
    "2. **Interview Materials**: Preparation materials including potential questions and suggested answers\n",
    "llm.call(\"Hello there Gemini! How are you doing today?\")\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"GROQ_API_KEY\"] \n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"GROQ_API_BASE\"] \n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'meta-llama/llama-4-scout-17b-16e-instruct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import libraries, APIs and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crewAI Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import (\n",
    "  FileReadTool,\n",
    "  MDXSearchTool,\n",
    "  SerperDevTool\n",
    ")\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "read_resume = FileReadTool(file_path='./fake_resume.md')\n",
    "semantic_search_resume = MDXSearchTool(mdx='./fake_resume.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uncomment and run the cell below if you wish to view `fake_resume.md` in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"./fake_resume.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Researcher\n",
    "researcher = Agent(\n",
    "    role=\"Tech Job Researcher\",\n",
    "    goal=\"Make sure to do amazing analysis on \"\n",
    "         \"job posting to help job applicants\",\n",
    "    tools = [search_tool],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"As a Job Researcher, your prowess in \"\n",
    "        \"analyzing and extracting critical \"\n",
    "        \"information from job descriptions is unmatched.\"\n",
    "        \"Your skills help pinpoint the necessary \"\n",
    "        \"qualifications and skills sought \"\n",
    "        \"by employers, forming the foundation for \"\n",
    "        \"effective application tailoring.\"\n",
    "    ),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Profiler\n",
    "profiler = Agent(\n",
    "    role=\"Personal Profiler for Engineers\",\n",
    "    goal=\"Do incredible research on job applicants \"\n",
    "         \"to help them stand out in the job market\",\n",
    "    tools = [search_tool, read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Equipped with analytical prowess, you dissect \"\n",
    "        \"and synthesize information \"\n",
    "        \"from diverse sources to craft comprehensive \"\n",
    "        \"personal and professional profiles, laying the \"\n",
    "        \"groundwork for personalized resume enhancements.\"\n",
    "    ),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Resume Strategist\n",
    "resume_strategist = Agent(\n",
    "    role=\"Resume Strategist for Engineers\",\n",
    "    goal=\"Find all the best ways to make a \"\n",
    "         \"resume stand out in the job market.\",\n",
    "    tools = [search_tool, read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"With a strategic mind and an eye for detail, you \"\n",
    "        \"excel at refining resumes to highlight the most \"\n",
    "        \"relevant skills and experiences, ensuring they \"\n",
    "        \"resonate perfectly with the job's requirements.\"\n",
    "    ),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 4: Interview Preparer\n",
    "interview_preparer = Agent(\n",
    "    role=\"Engineering Interview Preparer\",\n",
    "    goal=\"Create interview questions and talking points \"\n",
    "         \"based on the resume and job requirements\",\n",
    "    tools = [search_tool, read_resume, semantic_search_resume],\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Your role is crucial in anticipating the dynamics of \"\n",
    "        \"interviews. With your ability to formulate key questions \"\n",
    "        \"and talking points, you prepare candidates for success, \"\n",
    "        \"ensuring they can confidently address all aspects of the \"\n",
    "        \"job they are applying for.\"\n",
    "    ),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Researcher Agent: Extract Job Requirements\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the job description provided ({job_description}) \"\n",
    "        \"to extract key skills, experiences, and qualifications \"\n",
    "        \"required. Identify and categorize the requirements.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A structured list of job requirements, including necessary \"\n",
    "        \"skills, qualifications, and experiences.\"\n",
    "    ),\n",
    "    agent=researcher,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Profiler Agent: Compile Comprehensive Profile\n",
    "profile_task = Task(\n",
    "    description=(\n",
    "        \"Compile a detailed personal and professional profile \"\n",
    "        \"using the GitHub ({github_url}) URLs, and personal write-up \"\n",
    "        \"({personal_writeup}). Utilize tools to extract and \"\n",
    "        \"synthesize information from these sources.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A comprehensive profile document that includes skills, \"\n",
    "        \"project experiences, contributions, interests, and \"\n",
    "        \"communication style.\"\n",
    "    ),\n",
    "    agent=profiler,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can pass a list of tasks as `context` to a task.\n",
    "- The task then takes into account the output of those tasks in its execution.\n",
    "- The task will not run until it has the output(s) from those tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Resume Strategist Agent: Align Resume with Job Requirements\n",
    "resume_strategy_task = Task(\n",
    "    description=(\n",
    "        \"Using the profile and job requirements obtained from \"\n",
    "        \"previous tasks, tailor the resume to highlight the most \"\n",
    "        \"relevant areas. Employ tools to adjust and enhance the \"\n",
    "        \"resume content. Make sure this is the best resume even but \"\n",
    "        \"don't make up any information. Update every section, \"\n",
    "        \"including the initial summary, work experience, skills, \"\n",
    "        \"and education. All to better reflect the candidate's \"\n",
    "        \"abilities and how it matches the job description.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"An updated resume that effectively highlights the candidate's \"\n",
    "        \"qualifications and experiences relevant to the job.\"\n",
    "    ),\n",
    "    output_file=\"tailored_resume_text.md\",\n",
    "    context=[research_task, profile_task],\n",
    "    agent=resume_strategist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Interview Preparer Agent: Develop Interview Materials\n",
    "interview_preparation_task = Task(\n",
    "    description=(\n",
    "        \"Create a set of potential interview questions and talking \"\n",
    "        \"points based on the tailored resume and job requirements. \"\n",
    "        \"Utilize tools to generate relevant questions and discussion \"\n",
    "        \"points. Make sure to use these questions and talking points to \"\n",
    "        \"help the candidate highlight the main points of the resume \"\n",
    "        \"and how it matches the job description.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A document containing key questions and talking points \"\n",
    "        \"that the candidate should prepare for the initial interview.\"\n",
    "    ),\n",
    "    output_file=\"interview_materials_text.md\",\n",
    "    context=[research_task, profile_task, resume_strategy_task],\n",
    "    agent=interview_preparer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_application_crew = Crew(\n",
    "    agents=[researcher,\n",
    "            profiler,\n",
    "            resume_strategist,\n",
    "            interview_preparer],\n",
    "\n",
    "    tasks=[research_task,\n",
    "           profile_task,\n",
    "           resume_strategy_task,\n",
    "           interview_preparation_task],\n",
    "\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Job Description\n",
    "\n",
    "In this cell, you can enter the job description as text instead of providing a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your job description here\n",
    "job_description = \"\"\"ABOUT THE OPPORTUNITY\n",
    "\n",
    "The AI Foundation is offering a new opportunity to shape our AI initiatives. As the Senior Manager, Responsible AI Solutions, you'll be an individual contributor playing a key role in developing and implementing cutting-edge AI to address complex challenges and create significant impact. Reporting to the Global Director, Business Systems, you will collaborate with staff and consultants to guide the creation and deployment of AI solutions that align with the foundation's values and mission. This is a chance to be a champion for responsible AI, driving innovation and making a real difference.\n",
    "\n",
    "HOW YOU WILL CONTRIBUTE\n",
    "\n",
    "The Senior Manager, Responsible AI Solutions will perform the following and/or similar activities:\n",
    "\n",
    "Develop and implement ethical AI solutions: Collaborate with cross-functional teams to identify and translate business challenges into AI solutions. This involves assessing organizational needs, recommending ethical solutions, gathering requirements, designing and developing AI solutions, and deploying them into production environments.\n",
    "\n",
    "Manage and oversee AI program: Includes overall program and actions to plan, execute, and deliver AI projects, ensuring they are completed on time, within budget, and meet the required quality standards. This includes defining project scope, gaining insight and agreement from others, allocating resources, managing timelines, and mitigating risks.\n",
    "\n",
    "Define and track key performance indicators (KPIs): Establish and monitor KPIs to measure the success and impact of AI initiatives, ensuring alignment with business objectives and providing data-driven insights for continuous improvement.\n",
    "\n",
    "Evaluate and optimize AI model performance: Continuously monitor and evaluate the effectiveness and performance of AI models, identifying areas for improvement and implementing optimization strategies to reduce our carbon footprint and enhance accuracy, efficiency, and scalability.\n",
    "\n",
    "Ensure compliance with ethical AI practices: Adhere to ethical guidelines and data privacy regulations in all AI-related activities. Promote responsible AI development and deployment within the organization, considering potential biases, fairness, and transparency in AI systems.\n",
    "\n",
    "Monitor AI advancements: Remain up-to-date with emerging AI trends, technologies, and best practices. Research and recommend new AI tools and techniques to improve operational efficiency and drive innovation.\n",
    "\n",
    "Communicate effectively with stakeholders: Clearly and effectively communicate project solutions, requirements and updates, technical details, and AI concepts to technical and non-technical audiences, including senior management, business stakeholders, and team members. Translate complex technical information into clear business value for non-technical stakeholders.\n",
    "\n",
    "WHAT YOU WILL NEED\n",
    "\n",
    "Proficient in Python and AI frameworks (e.g., TensorFlow, PyTorch), with expertise in machine learning, deep learning, and natural language processing, including Gen AI technologies.\n",
    "\n",
    "Experienced with Generative AI tools and techniques (e.g., LLMs, LangChain, retrieval-augmented generation) and Agentic architecture.\n",
    "\n",
    "Familiar with AI Ops principles, including CI/CD pipelines, containerization, and automated testing.\n",
    "\n",
    "Skilled in optimizing AI workflows (e.g., distributed training, inference optimization, resource utilization - GPU/TPU) through collaboration with AI experts.\n",
    "\n",
    "Experienced in deploying AI models to production cloud environments (AWS, Azure, GCP), considering performance, cost, and latency.\n",
    "\n",
    "Adept at monitoring and troubleshooting model performance, addressing issues like performance drift and latency.\n",
    "\n",
    "Familiar with cloud computing platforms (AWS, Azure, GCP) and data technologies (SQL, Hadoop, Spark) for AI development and deployment.\n",
    "\n",
    "Demonstrated ability to recommend and apply AI solutions to real-world problems in content-rich domains.\n",
    "\n",
    "Experienced in working with large datasets and extracting insights from unstructured data.\n",
    "\n",
    "Strong understanding of content management systems, knowledge graphs, information retrieval techniques and experience with agile development methodologies.\n",
    "\n",
    "Excellent project management skills, including experience managing complex AI projects.\n",
    "\n",
    "Ways of working and engaging that align with the Foundation's mission, core values, and commitment to creating a culture of excellence.\n",
    "\n",
    "SALARY: The starting annualized gross salary is $150,000. The final offer is based on relevant experience and our commitment to internal equity.\n",
    "\n",
    "LOCATION: This position is based in the foundation's New York office. We operate in a hybrid model and require staff to be in the office three days per week.\n",
    "\n",
    "EMPLOYMENT TYPE: This is a permanent position.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Crew\n",
    "\n",
    "- Set the inputs for the execution of the crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_application_inputs = {\n",
    "    'job_description': job_description,\n",
    "    'github_url': 'https://github.com/padmanabhan-r',\n",
    "    'personal_writeup': \"\"\"Padmanabhan is an experienced AI & Data Science Manager with over 10 years of expertise in machine learning, data engineering, and business analytics. He holds a Master's degree in Computer Science with a specialization in Big Data and Data Science from Simon Fraser University, Canada. Currently leading a cross-functional team at Ford Motor Company, he focuses on building scalable ML solutions, Generative AI applications, and intelligent data pipelines that drive business decisions. Padmanabhan has a proven track record of delivering end-to-end AI products, developing predictive models, and creating actionable insights through dashboards and automation. He is passionate about solving complex data problems and thrives in roles that require a blend of technical depth, strategic thinking, and leadership. With strong programming skills in Python, R, and SQL, and hands-on experience with tools like Tableau, Power BI, and TensorFlow, Padmanabhan is well-suited for senior AI/ML roles that demand innovation, ownership, and impact.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: LLMs can provide different outputs for the same input, so what you get might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = job_application_crew.kickoff(inputs=job_application_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tailored resume\n",
    "display(Markdown(\"./tailored_resume_text.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the interview materials\n",
    "display(Markdown(\"./interview_materials_text.md\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
