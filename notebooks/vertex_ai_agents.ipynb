{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d1076",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown model publishers/google/models/gemini-1.5-flash; {'gs://google-cloud-aiplatform/schema/predict/instance/chat_generation_1.0.0.yaml': <class 'vertexai.preview.language_models._PreviewChatModel'>}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvertexai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreview\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatModel\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m chat_model = \u001b[43mChatModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/vertexai/_model_garden/_model_garden_models.py:289\u001b[39m, in \u001b[36m_ModelGardenModel.from_pretrained\u001b[39m\u001b[34m(cls, model_name)\u001b[39m\n\u001b[32m    278\u001b[39m credential_exception_str = (\n\u001b[32m    279\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUnable to authenticate your request.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDepending on your runtime environment, you can complete authentication by:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m )\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterface_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m auth_exceptions.GoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m auth_exceptions.GoogleAuthError(credential_exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/vertexai/_model_garden/_model_garden_models.py:206\u001b[39m, in \u001b[36m_from_pretrained\u001b[39m\u001b[34m(interface_class, model_name, publisher_model, tuned_vertex_model)\u001b[39m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interface_class._INSTANCE_SCHEMA_URI:\n\u001b[32m    202\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterface_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a correct model interface class since it does not have an instance schema URI.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     model_info = \u001b[43m_get_model_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema_to_class_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43minterface_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_INSTANCE_SCHEMA_URI\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_class\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    212\u001b[39m     schema_uri = publisher_model._gca_resource.predict_schemata.instance_schema_uri\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/vertexai/_model_garden/_model_garden_models.py:168\u001b[39m, in \u001b[36m_get_model_info\u001b[39m\u001b[34m(model_id, schema_to_class_map, interface_class, publisher_model_res, tuned_vertex_model)\u001b[39m\n\u001b[32m    163\u001b[39m     interface_class = schema_to_class_map.get(\n\u001b[32m    164\u001b[39m         publisher_model_res.predict_schemata.instance_schema_uri\n\u001b[32m    165\u001b[39m     )\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interface_class:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    169\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpublisher_model_res.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_to_class_map\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         )\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ModelInfo(\n\u001b[32m    173\u001b[39m     endpoint_name=endpoint_name,\n\u001b[32m    174\u001b[39m     interface_class=interface_class,\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m     tuning_model_id=tuning_model_id,\n\u001b[32m    178\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Unknown model publishers/google/models/gemini-1.5-flash; {'gs://google-cloud-aiplatform/schema/predict/instance/chat_generation_1.0.0.yaml': <class 'vertexai.preview.language_models._PreviewChatModel'>}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vertexai\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from IPython.display import display, Image\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "import openai\n",
    "from smolagents import ChatMessage, CodeAgent, Model, DuckDuckGoSearchTool\n",
    "from smolagents.agents import ActionStep\n",
    "from smolagents.tools import Tool, tool\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"your_service_account_key.json\"\n",
    "\n",
    "PROJECT_ID = \"your_project_id\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5005464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: VertexAIException BadRequestError - {\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid Endpoint name: projects/sinuous-cat-456509-r5/locations/us-central1/publishers/google/models/gemini-2.0-flash-001 .\",\n    \"status\": \"INVALID_ARGUMENT\"\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:1489\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   1488\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1489\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1490\u001b[39m     response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/llms/custom_httpx/http_handler.py:576\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    575\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/llms/custom_httpx/http_handler.py:558\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    557\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '400 Bad Request' for url 'https://us-central1-aiplatform.googleapis.com/v1/projects/sinuous-cat-456509-r5/locations/us-central1/publishers/google/models/gemini-2.0-flash-001%20:generateContent'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mVertexAIError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/main.py:2465\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   2461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   2462\u001b[39m     litellm_params.get(\u001b[33m\"\u001b[39m\u001b[33mbase_model\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2463\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m litellm_params[\u001b[33m\"\u001b[39m\u001b[33mbase_model\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2464\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     model_response = \u001b[43mvertex_chat_completion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2479\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[32m   2487\u001b[39m     \u001b[38;5;66;03m# Vertex Model Garden - OpenAI compatible models\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:1493\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   1492\u001b[39m     error_code = err.response.status_code\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m VertexAIError(\n\u001b[32m   1494\u001b[39m         status_code=error_code,\n\u001b[32m   1495\u001b[39m         message=err.response.text,\n\u001b[32m   1496\u001b[39m         headers=err.response.headers,\n\u001b[32m   1497\u001b[39m     )\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException:\n",
      "\u001b[31mVertexAIError\u001b[39m: {\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid Endpoint name: projects/sinuous-cat-456509-r5/locations/us-central1/publishers/google/models/gemini-2.0-flash-001 .\",\n    \"status\": \"INVALID_ARGUMENT\"\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m completion\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvertex_ai/gemini-2.0-flash-001 \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, how are you?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msinuous-cat-456509-r5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mus-central1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/utils.py:1255\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1252\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1253\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1254\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/utils.py:1133\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/main.py:3182\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3181\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3185\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2214\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2213\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/agents-exp/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:1217\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   1215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_exception.status_code == \u001b[32m400\u001b[39m:\n\u001b[32m   1216\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1217\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[32m   1218\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVertexAIException BadRequestError - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1219\u001b[39m         model=model,\n\u001b[32m   1220\u001b[39m         llm_provider=\u001b[33m\"\u001b[39m\u001b[33mvertex_ai\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1221\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m   1222\u001b[39m         response=httpx.Response(\n\u001b[32m   1223\u001b[39m             status_code=\u001b[32m400\u001b[39m,\n\u001b[32m   1224\u001b[39m             request=httpx.Request(\n\u001b[32m   1225\u001b[39m                 method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1226\u001b[39m                 url=\u001b[33m\"\u001b[39m\u001b[33mhttps://cloud.google.com/vertex-ai/\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1227\u001b[39m             ),\n\u001b[32m   1228\u001b[39m         ),\n\u001b[32m   1229\u001b[39m     )\n\u001b[32m   1230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_exception.status_code == \u001b[32m401\u001b[39m:\n\u001b[32m   1231\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: litellm.BadRequestError: VertexAIException BadRequestError - {\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid Endpoint name: projects/sinuous-cat-456509-r5/locations/us-central1/publishers/google/models/gemini-2.0-flash-001 .\",\n    \"status\": \"INVALID_ARGUMENT\"\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "\n",
    "response = completion(\n",
    "    model=\"vertex_ai/gemini-2.0-flash-001 \",\n",
    "    messages=[{\"content\": \"Hello, how are you?\", \"role\": \"user\"}],\n",
    "    vertex_project=\"sinuous-cat-456509-r5\",\n",
    "    vertex_location=\"us-central1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b55cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
